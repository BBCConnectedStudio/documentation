# Connected Studio Pilot Testing
There are three different kinds of testing we talk about at Connected Studio, which can become confusing. However they each have a different purpose and different methodology, so it's very useful to know the difference.

In a nutshell, the three types are:

* Audience Testing (AT) - how we test emotional engagement and audience impact

* Usability or ‘user’ Testing - how we test design, usability, ease of use

* User Acceptance Testing (UAT) - how we test if a correctly functioning product has been delivered

## Audience Testing (AT)

Purpose: To test the impact the pilot has on the audience, and their emotional engagement with the content. 

Who is responsible: This work is lead by a Connected Studio Development Producer and Audience Planner

How it is done: There are three main elements that help us measure how people respond to the pilot in this way:

1. Qualitative Testing (normally measured after the pilot build is delivered but before the Taster period)
 
2. Digital Analytics (measured throughout the pilot's Taster period)

3. Taster ratings and feedback questions (measured throughout the pilot's Taster period)

### Qualitative testing
If it is decided that a pilot will benefit from qualitative testing, this will be lead and planned for by a CS Audience Planner. The tests themselves are normally conducted by an external agency, and often take the form of one-on-one sessions where members of the public can try out the pilot and be asked for their feedback. However, the format may vary.
Effort is required from both the BBC Editorial team and the indie in order to help write a testing brief. This normally takes the form of one or two dedicated sessions about half way through the pilot build, which are facilitated by the Audience Planner, and known as Audience Design Sessions (ADS).

Please note: qualitative testing is budgeted for seperately, i.e. should not be included in the SoW produced by the indie.

### Digital Analytics
Some pilots will include digital analytics in order to track certain interactions within the content, and thus gather information about particular user behaviour. For example, this could be used to measure how many people interacted in a certain way, or how long they interacted for.
An Audience Planner and Development Producer will advise if this is appropriate for a given pilot. If so, The ‘tagging spec’ containing a list of what will be tagged, and the correct tag names, will be provided by the Connected Studio and Taster team. The tags themselves will need to be implemented by the indie (technical information on the BBC’s stats library can be found [here](pilot-technical-pack.md)) and the Statement of Work should reflect this. Data analysis and reporting on the analytics are the responsibility of the CS and Taster team.

### Taster Ratings and Feedback Questions
Taster encourages users to leave a rating (out of 5) and answer about 6 feedback questions. These are normally a mixture of questions gathering information about the audience demographic (age, gender) and their thoughts about the pilot (what was your favourite part? what else would you like to see? etc). All are multiple choice, single answer questions. The development Producer and Audience Planner will lead this with input from the pilot team, prior to the Taster launch.

## Usability Testing

Purpose: To test basic functionaility and usability of the app, and refine the design 

Who is responsible: This work is lead by the development team (the indie) with input from the BBC Editorial team and Development Producer

How it is done: Some indies may wish to include some form of iterative usability testing with audience members as part of the design process. If they wish to do this it needs to be outlined and agreed in the Statement of Work. For the majority of pilots, however, usability testing is a more informal 'guerilla testing' process. Typically pilot teams agree milestones at which to test certain elements of the prototype, either amongst themselves or with their wider teams, and feedback to the development team.

## User Acceptance Testing (UAT) 

Purpose: To check that a correctly functioning product has been delivered

Who is responsible: This work is lead by the Development Producer and Taster Technical Lead

How it is done: This involves reviewing and signing off basic functionality, editorial content, and technical implementation by the relevant people at the BBC, and happens upon delivery of the prototype.
